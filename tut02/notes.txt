Hello again and welcome to week 2!

In this tutorial we will be looking at:
    - Recursion
    - Analysis of Algorithms

Admin stuff:
    - This code is available on a Github repository
    - You can get lab01 handmarked today or next week
    - This week's lab has no handmarking (fully automarked)



So, what is recursion?
    - Recursion is a way of solving problems where a problem is solved by
        solving a small part of it first, and then leaving the rest of it
        as a (smaller), almost identical "subproblem".

We have a problem: we need to climb the rainbow stairs
    - Iterative:
        while i am not at the top of the staircase:
            climb one step

    - Recursively:
        (base case)
        if i am at the top:
            do nothing, because I am already at the top

        (recursive case)
        else:
            climb one step, and then climb the rest of the staircase



Why should we use recursion?
    - It can make our code look a lot simpler
    - Some problems are easier to think about recursively
    - Some programming languages do not have loops (you have to use recursion!)


Downsides of recursion:
    - Takes up a lot of memory
    - Can be difficult to read (complicated)
    - Can be slower than an iterative solution


Linked lists and recurstion:
    - You can think of a linked list as either:
        - An empty list, or
        - A node, and the rest of the list (sublist)



Analysis of algorithms
What is big-O?
    - A way of quantitatively describing how fast or slow an algorithm runs at scale

How do we calculate it?
    - e.g. T(n) = 2n(n + 3log(n))

    1. Remove the coefficients
    T(n) =  2n(n + 3log(n))
         = 2n^2 + 6 * nlog(n)
         -> n^2 + nlog(n)

    2. Take the most dominant term
         -> O(n^2)
